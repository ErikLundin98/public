data.log.table
calc_accuracy(data.log.table)
library(e1071)
# SVM with regular, rectangular kernel
data.svm = svm(as.factor(label) ~ ., data.train, type='C-classification', kernel='linear')
data.svm.predictions = predict(data.svm, data.test)
data.svm.table = table(data.svm.predictions, data.test$label)
calc_accuracy(data.svm.table)
library(kernlab)
# SVM with radial kernel
data.ksvm.1= ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='rbfdot')
data.ksvm.1.predictions = predict(data.ksvm.1, data.test)
data.ksvm.1.table = table(data.ksvm.1.predictions, data.test$label)
calc_accuracy(data.ksvm.1.table)
data.ksvm.2 = ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='laplacedot')
data.ksvm.2.predictions = predict(data.ksvm.2, data.test)
data.ksvm.2.table = table(data.ksvm.2.predictions, data.test$label)
calc_accuracy(data.ksvm.2.table)
data.ksvm.3 = ksvm(as.factor(label) ~ ., data.train, type="spoc-svc", kernel='rbfdot')
data.ksvm.3.predictions = predict(data.ksvm.3, data.test)
data.ksvm.3.table = table(data.ksvm.3.predictions, data.test$label)
calc_accuracy(data.ksvm.3.table)
# Take a list of classifiers and a dataset and return a list of the model's predictions
all_predictions = function(classifiers, data) {
all_preds = data.frame(matrix(NA, nrow=nrow(data), ncol=length(classifiers)))
for(i in 1:length(classifiers)) {
prediction = predict(classifiers[[i]], data)
if(class(prediction) != "factor") {
prediction = as.factor(prediction$class)
}
all_preds[, i] = (prediction)
}
return(all_preds)
}
# Select the most likely class by calculating the "likelihood" for each class according to different model's accuracies
weighted_predictions = function(separate_predictions, weights) {
res = apply(separate_predictions, 1, function(x) {
score_per_class = replicate(10, 0)
for(classifier in 1:length(x)) {
score_per_class[as.numeric(x[classifier])] = score_per_class[as.numeric(x[classifier])] + weights[classifier, as.numeric(x[classifier])]
}
x = which.max(score_per_class)
})
return(res)
}
# Take a confusion matrix and calculate the likelihood that the actual class is the predicted one
# P(class is correct | class = A) = #times the classifier guessed A correctly / #times the classifier guessed A
calc_accuracy_per_class = function(cmatr) {
n = dim(cmatr)[1]
weights = numeric(n)
for(i in 1:n) {
weights[i] = cmatr[i, i]/sum(cmatr[i,])
}
return(weights)
}
# Take a list of classifiers and data and computes the accuracies (weights) per class for all classifiers
calc_weights_with_data = function(classifiers, data) {
predictions = all_predictions(classifiers, data)
tables = lapply(predictions, function(x) table(x, data$label))
accuracies = lapply(tables, calc_accuracy_per_class)
weights = matrix(unlist(accuracies), ncol=10, byrow=TRUE)
return(weights)
}
classifiers = list(data.rda, data.mda, data.ksvm.1, data.ksvm.2, data.ksvm.3)
weights = calc_weights_with_data(classifiers, data.test)
all_testpred = all_predictions(classifiers, data.test)
weights
ensemble_testpred = weighted_predictions(all_testpred, weights)
ensemble_table = table(as.numeric(ensemble_testpred), data.test$label)
ensemble_table
calc_accuracy(ensemble_table)
library(caret)
# Load the data
raw_data = read.csv("data.csv")
# Visualize the dataset
head(raw_data)
# Remove filename feature
data = subset(raw_data, select = -filename )
# Scale the data to have a mean of 0 and a standard deviation of one
data[-29] = lapply(data[-29], scale)
# Store label strings in separate array and label dataframe samples by index instead (to get numeric values)
# Cast labels to factors
data.labels = sort(unique(data$label))
data = transform(data, label = match(label, data.labels))
# Data after cleaning
head(data)
library(corrplot)
library(ggplot2)
library(tidyr)
corrplot(cor(data))
ggplot(gather(data), aes(value)) +
geom_histogram(bins = ncol(data)) +
facet_wrap(~key, scales = 'free_x')
data.pca = prcomp(data, retx=TRUE)
summary(data.pca)
library(ggfortify)
library(factoextra)
# Plot the PCA, showing eigenvectors of the result
autoplot(data.pca, data=data, loadings=TRUE, colour="label", loadings.label=TRUE, loadings.label.size=3)
fviz_eig(data.pca)
# Split into training and validation data, with uniform distribution among labels
training_indices = createDataPartition(data$label, p=0.75, list=FALSE)
data.train = data[training_indices,]
data.test = data[-training_indices,]
library(psych)
calc_accuracy = function(cmatr) {
return(tr(cmatr)/sum(cmatr))
}
library(MASS)
data.lda = lda(label ~ ., data=data.train)
data.lda.predictions = predict(data.lda, data.test)
data.lda.table = table(as.numeric(data.lda.predictions$class), data.test$label)
data.lda.table
mean(data.lda.predictions$class==data.test$label)
data.qda = qda(label~., data=data.train)
data.qda.predictions = predict(data.qda, data.test)
data.qda.table = table(as.numeric(data.qda.predictions$class), data.test$label)
data.qda.table
mean(data.qda.predictions$class==data.test$label)
library(mda)
data.mda = mda(label~., data=data.train)
data.mda.predictions = predict(data.mda, data.test)
data.mda.table = table(as.numeric(data.mda.predictions), data.test$label)
data.mda.table
mean(data.mda.predictions==data.test$label)
data.fda = mda(label~., data=data.train, method=polyreg)
data.fda.predictions = predict(data.fda, data.test)
data.fda.table = table(as.numeric(data.lda.predictions$class), data.test$label)
data.fda.table
mean(data.fda.predictions==data.test$label)
library(klaR)
data.rda = rda(label~., data=data.train)
data.rda.predictions = predict(data.rda, data.test)
data.rda.table = table(as.numeric(data.rda.predictions$class), data.test$label)
data.rda.table
mean(data.rda.predictions$class==data.test$label)
library(kknn)
neighbors_to_test = ceiling(sqrt(dim(data.train)[1]))
data.knn = train.kknn(as.factor(label) ~ ., data.train, kmax=neighbors_to_test, distance=2, kernel='gaussian')
data.knn.predictions = predict(data.knn, data.test)
data.knn.table = table(data.knn.predictions, data.test$label)
data.knn.table
calc_accuracy(data.knn.table)
library(nnet)
data.log = multinom(as.factor(label) ~ ., data=data.train)
data.log.predictions = predict(data.log, data.test)
data.log.table = table(data.log.predictions, data.test$label)
data.log.table
calc_accuracy(data.log.table)
library(e1071)
# SVM with regular, rectangular kernel
data.svm = svm(as.factor(label) ~ ., data.train, type='C-classification', kernel='linear')
data.svm.predictions = predict(data.svm, data.test)
data.svm.table = table(data.svm.predictions, data.test$label)
calc_accuracy(data.svm.table)
library(kernlab)
# SVM with radial kernel
data.ksvm.1= ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='rbfdot')
data.ksvm.1.predictions = predict(data.ksvm.1, data.test)
data.ksvm.1.table = table(data.ksvm.1.predictions, data.test$label)
calc_accuracy(data.ksvm.1.table)
data.ksvm.2 = ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='laplacedot')
data.ksvm.2.predictions = predict(data.ksvm.2, data.test)
data.ksvm.2.table = table(data.ksvm.2.predictions, data.test$label)
calc_accuracy(data.ksvm.2.table)
data.ksvm.3 = ksvm(as.factor(label) ~ ., data.train, type="spoc-svc", kernel='rbfdot')
data.ksvm.3.predictions = predict(data.ksvm.3, data.test)
data.ksvm.3.table = table(data.ksvm.3.predictions, data.test$label)
calc_accuracy(data.ksvm.3.table)
# Take a list of classifiers and a dataset and return a list of the model's predictions
all_predictions = function(classifiers, data) {
all_preds = data.frame(matrix(NA, nrow=nrow(data), ncol=length(classifiers)))
for(i in 1:length(classifiers)) {
prediction = predict(classifiers[[i]], data)
if(class(prediction) != "factor") {
prediction = as.factor(prediction$class)
}
all_preds[, i] = (prediction)
}
return(all_preds)
}
# Select the most likely class by calculating the "likelihood" for each class according to different model's accuracies
weighted_predictions = function(separate_predictions, weights) {
res = apply(separate_predictions, 1, function(x) {
score_per_class = replicate(10, 0)
for(classifier in 1:length(x)) {
score_per_class[as.numeric(x[classifier])] = score_per_class[as.numeric(x[classifier])] + weights[classifier, as.numeric(x[classifier])]
}
x = which.max(score_per_class)
})
return(res)
}
# Take a confusion matrix and calculate the likelihood that the actual class is the predicted one
# P(class is correct | class = A) = #times the classifier guessed A correctly / #times the classifier guessed A
calc_accuracy_per_class = function(cmatr) {
n = dim(cmatr)[1]
weights = numeric(n)
for(i in 1:n) {
weights[i] = cmatr[i, i]/sum(cmatr[i,])
}
return(weights)
}
# Take a list of classifiers and data and computes the accuracies (weights) per class for all classifiers
calc_weights_with_data = function(classifiers, data) {
predictions = all_predictions(classifiers, data)
tables = lapply(predictions, function(x) table(x, data$label))
accuracies = lapply(tables, calc_accuracy_per_class)
weights = matrix(unlist(accuracies), ncol=10, byrow=TRUE)
return(weights)
}
classifiers = list(data.rda, data.mda, data.ksvm.1, data.ksvm.2, data.ksvm.3)
weights = calc_weights_with_data(classifiers, data.test)
all_testpred = all_predictions(classifiers, data.test)
weights
ensemble_testpred = weighted_predictions(all_testpred, weights)
ensemble_table = table(as.numeric(ensemble_testpred), data.test$label)
ensemble_table
calc_accuracy(ensemble_table)
library(caret)
# Load the data
raw_data = read.csv("data.csv")
# Visualize the dataset
head(raw_data)
# Remove filename feature
data = subset(raw_data, select = -filename )
# Scale the data to have a mean of 0 and a standard deviation of one
data[-29] = lapply(data[-29], scale)
# Store label strings in separate array and label dataframe samples by index instead (to get numeric values)
# Cast labels to factors
data.labels = sort(unique(data$label))
data = transform(data, label = match(label, data.labels))
# Data after cleaning
head(data)
library(corrplot)
library(ggplot2)
library(tidyr)
corrplot(cor(data))
ggplot(gather(data), aes(value)) +
geom_histogram(bins = ncol(data)) +
facet_wrap(~key, scales = 'free_x')
data.pca = prcomp(data, retx=TRUE)
summary(data.pca)
library(ggfortify)
library(factoextra)
# Plot the PCA, showing eigenvectors of the result
autoplot(data.pca, data=data, loadings=TRUE, colour="label", loadings.label=TRUE, loadings.label.size=3)
fviz_eig(data.pca)
# Split into training and validation data, with uniform distribution among labels
training_indices = createDataPartition(data$label, p=0.75, list=FALSE)
data.train = data[training_indices,]
data.test = data[-training_indices,]
library(psych)
calc_accuracy = function(cmatr) {
return(tr(cmatr)/sum(cmatr))
}
library(MASS)
data.lda = lda(label ~ ., data=data.train)
data.lda.predictions = predict(data.lda, data.test)
data.lda.table = table(as.numeric(data.lda.predictions$class), data.test$label)
data.lda.table
mean(data.lda.predictions$class==data.test$label)
data.qda = qda(label~., data=data.train)
data.qda.predictions = predict(data.qda, data.test)
data.qda.table = table(as.numeric(data.qda.predictions$class), data.test$label)
data.qda.table
mean(data.qda.predictions$class==data.test$label)
library(mda)
data.mda = mda(label~., data=data.train)
data.mda.predictions = predict(data.mda, data.test)
data.mda.table = table(as.numeric(data.mda.predictions), data.test$label)
data.mda.table
mean(data.mda.predictions==data.test$label)
data.fda = mda(label~., data=data.train, method=polyreg)
data.fda.predictions = predict(data.fda, data.test)
data.fda.table = table(as.numeric(data.lda.predictions$class), data.test$label)
data.fda.table
mean(data.fda.predictions==data.test$label)
library(klaR)
data.rda = rda(label~., data=data.train)
data.rda.predictions = predict(data.rda, data.test)
data.rda.table = table(as.numeric(data.rda.predictions$class), data.test$label)
data.rda.table
mean(data.rda.predictions$class==data.test$label)
library(kknn)
neighbors_to_test = ceiling(sqrt(dim(data.train)[1]))
data.knn = train.kknn(as.factor(label) ~ ., data.train, kmax=neighbors_to_test, distance=2, kernel='gaussian')
data.knn.predictions = predict(data.knn, data.test)
data.knn.table = table(data.knn.predictions, data.test$label)
data.knn.table
calc_accuracy(data.knn.table)
library(nnet)
data.log = multinom(as.factor(label) ~ ., data=data.train)
data.log.predictions = predict(data.log, data.test)
data.log.table = table(data.log.predictions, data.test$label)
data.log.table
calc_accuracy(data.log.table)
library(e1071)
# SVM with regular, rectangular kernel
data.svm = svm(as.factor(label) ~ ., data.train, type='C-classification', kernel='linear')
data.svm.predictions = predict(data.svm, data.test)
data.svm.table = table(data.svm.predictions, data.test$label)
calc_accuracy(data.svm.table)
library(kernlab)
# SVM with radial kernel
data.ksvm.1= ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='rbfdot')
data.ksvm.1.predictions = predict(data.ksvm.1, data.test)
data.ksvm.1.table = table(data.ksvm.1.predictions, data.test$label)
calc_accuracy(data.ksvm.1.table)
data.ksvm.2 = ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='laplacedot')
data.ksvm.2.predictions = predict(data.ksvm.2, data.test)
data.ksvm.2.table = table(data.ksvm.2.predictions, data.test$label)
calc_accuracy(data.ksvm.2.table)
data.ksvm.3 = ksvm(as.factor(label) ~ ., data.train, type="spoc-svc", kernel='rbfdot')
data.ksvm.3.predictions = predict(data.ksvm.3, data.test)
data.ksvm.3.table = table(data.ksvm.3.predictions, data.test$label)
calc_accuracy(data.ksvm.3.table)
# Take a list of classifiers and a dataset and return a list of the model's predictions
all_predictions = function(classifiers, data) {
all_preds = data.frame(matrix(NA, nrow=nrow(data), ncol=length(classifiers)))
for(i in 1:length(classifiers)) {
prediction = predict(classifiers[[i]], data)
if(class(prediction) != "factor") {
prediction = as.factor(prediction$class)
}
all_preds[, i] = (prediction)
}
return(all_preds)
}
# Select the most likely class by calculating the "likelihood" for each class according to different model's accuracies
weighted_predictions = function(separate_predictions, weights) {
res = apply(separate_predictions, 1, function(x) {
score_per_class = replicate(10, 0)
for(classifier in 1:length(x)) {
score_per_class[as.numeric(x[classifier])] = score_per_class[as.numeric(x[classifier])] + weights[classifier, as.numeric(x[classifier])]
}
x = which.max(score_per_class)
})
return(res)
}
# Take a confusion matrix and calculate the likelihood that the actual class is the predicted one
# P(class is correct | class = A) = #times the classifier guessed A correctly / #times the classifier guessed A
calc_accuracy_per_class = function(cmatr) {
n = dim(cmatr)[1]
weights = numeric(n)
for(i in 1:n) {
weights[i] = cmatr[i, i]/sum(cmatr[i,])
}
return(weights)
}
# Take a list of classifiers and data and computes the accuracies (weights) per class for all classifiers
calc_weights_with_data = function(classifiers, data) {
predictions = all_predictions(classifiers, data)
tables = lapply(predictions, function(x) table(x, data$label))
accuracies = lapply(tables, calc_accuracy_per_class)
weights = matrix(unlist(accuracies), ncol=10, byrow=TRUE)
return(weights)
}
classifiers = list(data.rda, data.mda, data.ksvm.1, data.ksvm.2, data.ksvm.3)
weights = calc_weights_with_data(classifiers, data.test)
all_testpred = all_predictions(classifiers, data.test)
weights
ensemble_testpred = weighted_predictions(all_testpred, weights)
ensemble_table = table(as.numeric(ensemble_testpred), data.test$label)
ensemble_table
calc_accuracy(ensemble_table)
library(caret)
# Load the data
raw_data = read.csv("data.csv")
# Visualize the dataset
head(raw_data)
# Remove filename feature
data = subset(raw_data, select = -filename )
# Scale the data to have a mean of 0 and a standard deviation of one
data[-29] = lapply(data[-29], scale)
# Store label strings in separate array and label dataframe samples by index instead (to get numeric values)
# Cast labels to factors
data.labels = sort(unique(data$label))
data = transform(data, label = match(label, data.labels))
# Data after cleaning
head(data)
library(corrplot)
library(ggplot2)
library(tidyr)
corrplot(cor(data))
ggplot(gather(data), aes(value)) +
geom_histogram(bins = ncol(data)) +
facet_wrap(~key, scales = 'free_x')
data.pca = prcomp(data, retx=TRUE)
summary(data.pca)
library(ggfortify)
library(factoextra)
# Plot the PCA, showing eigenvectors of the result
autoplot(data.pca, data=data, loadings=TRUE, colour="label", loadings.label=TRUE, loadings.label.size=3)
fviz_eig(data.pca)
# Split into training and validation data, with uniform distribution among labels
training_indices = createDataPartition(data$label, p=0.75, list=FALSE)
data.train = data[training_indices,]
data.test = data[-training_indices,]
library(psych)
calc_accuracy = function(cmatr) {
return(tr(cmatr)/sum(cmatr))
}
library(MASS)
data.lda = lda(label ~ ., data=data.train)
data.lda.predictions = predict(data.lda, data.test)
data.lda.table = table(as.numeric(data.lda.predictions$class), data.test$label)
data.lda.table
mean(data.lda.predictions$class==data.test$label)
data.qda = qda(label~., data=data.train)
data.qda.predictions = predict(data.qda, data.test)
data.qda.table = table(as.numeric(data.qda.predictions$class), data.test$label)
data.qda.table
mean(data.qda.predictions$class==data.test$label)
library(mda)
data.mda = mda(label~., data=data.train)
data.mda.predictions = predict(data.mda, data.test)
data.mda.table = table(as.numeric(data.mda.predictions), data.test$label)
data.mda.table
mean(data.mda.predictions==data.test$label)
data.fda = mda(label~., data=data.train, method=polyreg)
data.fda.predictions = predict(data.fda, data.test)
data.fda.table = table(as.numeric(data.lda.predictions$class), data.test$label)
data.fda.table
mean(data.fda.predictions==data.test$label)
library(klaR)
data.rda = rda(label~., data=data.train)
data.rda.predictions = predict(data.rda, data.test)
data.rda.table = table(as.numeric(data.rda.predictions$class), data.test$label)
data.rda.table
mean(data.rda.predictions$class==data.test$label)
library(kknn)
neighbors_to_test = ceiling(sqrt(dim(data.train)[1]))
data.knn = train.kknn(as.factor(label) ~ ., data.train, kmax=neighbors_to_test, distance=2, kernel='gaussian')
data.knn.predictions = predict(data.knn, data.test)
data.knn.table = table(data.knn.predictions, data.test$label)
data.knn.table
calc_accuracy(data.knn.table)
library(nnet)
data.log = multinom(as.factor(label) ~ ., data=data.train)
data.log.predictions = predict(data.log, data.test)
data.log.table = table(data.log.predictions, data.test$label)
data.log.table
calc_accuracy(data.log.table)
library(e1071)
# SVM with regular, rectangular kernel
data.svm = svm(as.factor(label) ~ ., data.train, type='C-classification', kernel='linear')
data.svm.predictions = predict(data.svm, data.test)
data.svm.table = table(data.svm.predictions, data.test$label)
calc_accuracy(data.svm.table)
library(kernlab)
# SVM with radial kernel
data.ksvm.1= ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='rbfdot')
data.ksvm.1.predictions = predict(data.ksvm.1, data.test)
data.ksvm.1.table = table(data.ksvm.1.predictions, data.test$label)
calc_accuracy(data.ksvm.1.table)
data.ksvm.2 = ksvm(as.factor(label) ~ ., data.train, type="nu-svc", kernel='laplacedot')
data.ksvm.2.predictions = predict(data.ksvm.2, data.test)
data.ksvm.2.table = table(data.ksvm.2.predictions, data.test$label)
calc_accuracy(data.ksvm.2.table)
data.ksvm.3 = ksvm(as.factor(label) ~ ., data.train, type="spoc-svc", kernel='rbfdot')
data.ksvm.3.predictions = predict(data.ksvm.3, data.test)
data.ksvm.3.table = table(data.ksvm.3.predictions, data.test$label)
calc_accuracy(data.ksvm.3.table)
# Take a list of classifiers and a dataset and return a list of the model's predictions
all_predictions = function(classifiers, data) {
all_preds = data.frame(matrix(NA, nrow=nrow(data), ncol=length(classifiers)))
for(i in 1:length(classifiers)) {
prediction = predict(classifiers[[i]], data)
if(class(prediction) != "factor") {
prediction = as.factor(prediction$class)
}
all_preds[, i] = (prediction)
}
return(all_preds)
}
# Select the most likely class by calculating the "likelihood" for each class according to different model's accuracies
weighted_predictions = function(separate_predictions, weights) {
res = apply(separate_predictions, 1, function(x) {
score_per_class = replicate(10, 0)
for(classifier in 1:length(x)) {
score_per_class[as.numeric(x[classifier])] = score_per_class[as.numeric(x[classifier])] + weights[classifier, as.numeric(x[classifier])]
}
x = which.max(score_per_class)
})
return(res)
}
# Take a confusion matrix and calculate the likelihood that the actual class is the predicted one
# P(class is correct | class = A) = #times the classifier guessed A correctly / #times the classifier guessed A
calc_accuracy_per_class = function(cmatr) {
n = dim(cmatr)[1]
weights = numeric(n)
for(i in 1:n) {
weights[i] = cmatr[i, i]/sum(cmatr[i,])
}
return(weights)
}
# Take a list of classifiers and data and computes the accuracies (weights) per class for all classifiers
calc_weights_with_data = function(classifiers, data) {
predictions = all_predictions(classifiers, data)
tables = lapply(predictions, function(x) table(x, data$label))
accuracies = lapply(tables, calc_accuracy_per_class)
weights = matrix(unlist(accuracies), ncol=10, byrow=TRUE)
return(weights)
}
classifiers = list(data.rda, data.mda, data.ksvm.1, data.ksvm.2, data.ksvm.3)
weights = calc_weights_with_data(classifiers, data.test)
all_testpred = all_predictions(classifiers, data.test)
weights
ensemble_testpred = weighted_predictions(all_testpred, weights)
ensemble_table = table(as.numeric(ensemble_testpred), data.test$label)
ensemble_table
calc_accuracy(ensemble_table)
